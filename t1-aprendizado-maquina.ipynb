{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primeiro Prompt: k-NN\n",
    "Implemente um algoritmo do Knn em python sem usar scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui está uma implementação básica do algoritmo K-Nearest Neighbors (KNN) em Python, sem o uso da biblioteca `scikit-learn`. Esse código implementa o KNN de forma simples e eficiente, usando apenas bibliotecas padrão do Python como `math` e `collections` para calcular as distâncias e determinar os vizinhos mais próximos.\n",
    "\n",
    "### Passos principais do KNN:\n",
    "1. Calcular a distância entre o ponto de teste e todos os pontos de treino.\n",
    "2. Selecionar os `k` vizinhos mais próximos com base nas distâncias.\n",
    "3. Realizar a votação majoritária (para classificação) ou calcular a média (para regressão) entre os vizinhos selecionados.\n",
    "\n",
    "Aqui está o código de exemplo:\n",
    "\n",
    "```python\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "# Função para calcular a distância Euclidiana entre dois pontos\n",
    "def euclidean_distance(point1, point2):\n",
    "    return math.sqrt(sum((x - y) ** 2 for x, y in zip(point1, point2)))\n",
    "\n",
    "# Implementação do algoritmo KNN\n",
    "class KNN:\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "        self.data = None\n",
    "        self.labels = None\n",
    "\n",
    "    # Função para treinar o modelo com os dados de treino\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.data = X_train\n",
    "        self.labels = y_train\n",
    "\n",
    "    # Função para prever o rótulo (classificação)\n",
    "    def predict(self, X_test):\n",
    "        predictions = []\n",
    "        for test_point in X_test:\n",
    "            # Calcular a distância de todos os pontos de treino\n",
    "            distances = [(euclidean_distance(test_point, train_point), label) \n",
    "                         for train_point, label in zip(self.data, self.labels)]\n",
    "            # Ordenar as distâncias e pegar os k vizinhos mais próximos\n",
    "            sorted_distances = sorted(distances)[:self.k]\n",
    "            # Coletar os rótulos dos vizinhos mais próximos\n",
    "            k_nearest_labels = [label for _, label in sorted_distances]\n",
    "            # Votação majoritária\n",
    "            most_common_label = Counter(k_nearest_labels).most_common(1)[0][0]\n",
    "            predictions.append(most_common_label)\n",
    "        return predictions\n",
    "\n",
    "# Exemplo de uso\n",
    "if __name__ == \"__main__\":\n",
    "    # Dados de treino (4 amostras de 2 features)\n",
    "    X_train = [[1, 2], [2, 3], [3, 4], [5, 6]]\n",
    "    y_train = [0, 0, 1, 1]  # Rótulos correspondentes\n",
    "\n",
    "    # Dados de teste (1 amostra de 2 features)\n",
    "    X_test = [[1.5, 2.5]]\n",
    "\n",
    "    # Instancia o modelo KNN\n",
    "    knn = KNN(k=3)\n",
    "    \n",
    "    # Treina o modelo\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # Faz a previsão\n",
    "    prediction = knn.predict(X_test)\n",
    "    \n",
    "    print(\"Predição:\", prediction)\n",
    "```\n",
    "\n",
    "### Explicação:\n",
    "- **euclidean_distance**: Calcula a distância euclidiana entre dois pontos.\n",
    "- **KNN**:\n",
    "  - `__init__(self, k=3)`: Inicializa o modelo com o número de vizinhos `k`.\n",
    "  - `fit(self, X_train, y_train)`: Armazena os dados de treino e seus rótulos.\n",
    "  - `predict(self, X_test)`: Faz a previsão para novos dados de teste, calculando a distância de cada ponto de teste para todos os pontos de treino, selecionando os `k` mais próximos e retornando o rótulo mais comum (votação majoritária).\n",
    "\n",
    "Você pode alterar a função de distância para outras métricas, como distância de Manhattan, ou ajustar o valor de `k` conforme necessário.\n",
    "\n",
    "Se precisar de mais informações ou ajustes, estou à disposição!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "# Função para calcular a distância Euclidiana entre dois pontos\n",
    "def euclidean_distance(point1, point2):\n",
    "    return math.sqrt(sum((x - y) ** 2 for x, y in zip(point1, point2)))\n",
    "\n",
    "# Implementação do algoritmo KNN\n",
    "class KNN:\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "        self.data = None\n",
    "        self.labels = None\n",
    "\n",
    "    # Função para treinar o modelo com os dados de treino\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.data = X_train\n",
    "        self.labels = y_train\n",
    "\n",
    "    # Função para prever o rótulo (classificação)\n",
    "    def predict(self, X_test):\n",
    "        predictions = []\n",
    "        for test_point in X_test:\n",
    "            # Calcular a distância de todos os pontos de treino\n",
    "            distances = [(euclidean_distance(test_point, train_point), label) \n",
    "                         for train_point, label in zip(self.data, self.labels)]\n",
    "            # Ordenar as distâncias e pegar os k vizinhos mais próximos\n",
    "            sorted_distances = sorted(distances)[:self.k]\n",
    "            # Coletar os rótulos dos vizinhos mais próximos\n",
    "            k_nearest_labels = [label for _, label in sorted_distances]\n",
    "            # Votação majoritária\n",
    "            most_common_label = Counter(k_nearest_labels).most_common(1)[0][0]\n",
    "            predictions.append(most_common_label)\n",
    "        return predictions\n",
    "\n",
    "# Exemplo de uso\n",
    "if __name__ == \"__main__\":\n",
    "    # Dados de treino (4 amostras de 2 features)\n",
    "    X_train = [[1, 2], [2, 3], [3, 4], [5, 6]]\n",
    "    y_train = [0, 0, 1, 1]  # Rótulos correspondentes\n",
    "\n",
    "    # Dados de teste (1 amostra de 2 features)\n",
    "    X_test = [[1.5, 2.5]]\n",
    "\n",
    "    # Instancia o modelo KNN\n",
    "    knn = KNN(k=3)\n",
    "    \n",
    "    # Treina o modelo\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # Faz a previsão\n",
    "    prediction = knn.predict(X_test)\n",
    "    \n",
    "    print(\"Predição:\", prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segundo prompt: Naive Bayes\n",
    "Implemente um algoritmo de Naive Bayes em python sem usar scikit-learn, ou seja, from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui está uma implementação básica de um classificador Naive Bayes \"from scratch\" em Python, sem usar `scikit-learn`. Essa abordagem é baseada no teorema de Bayes e na suposição de que as características são independentes entre si (daí o nome \"Naive\").\n",
    "\n",
    "### Passos principais:\n",
    "1. **Treinamento**: Calcular a probabilidade condicional de cada classe com base nas características (estimativas de máxima verossimilhança).\n",
    "2. **Predição**: Para cada novo exemplo, calcular a probabilidade posterior de cada classe, dada a entrada, e selecionar a classe com a maior probabilidade.\n",
    "\n",
    "Para simplificar, vamos implementar a versão para classificação binária ou multiclasse, assumindo que os atributos são contínuos (usaremos a função densidade de probabilidade Gaussiana).\n",
    "\n",
    "### Implementação:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "class NaiveBayes:\n",
    "    def fit(self, X_train, y_train):\n",
    "        # Separar por classe\n",
    "        self.classes = np.unique(y_train)\n",
    "        self.mean = {}\n",
    "        self.var = {}\n",
    "        self.priors = {}\n",
    "        \n",
    "        # Para cada classe\n",
    "        for c in self.classes:\n",
    "            X_c = X_train[y_train == c]\n",
    "            self.mean[c] = np.mean(X_c, axis=0)\n",
    "            self.var[c] = np.var(X_c, axis=0)\n",
    "            self.priors[c] = X_c.shape[0] / X_train.shape[0]\n",
    "\n",
    "    # Função para calcular a densidade de probabilidade Gaussiana\n",
    "    def gaussian_pdf(self, class_idx, x):\n",
    "        mean = self.mean[class_idx]\n",
    "        var = self.var[class_idx]\n",
    "        numerator = np.exp(-(x - mean) ** 2 / (2 * var))\n",
    "        denominator = np.sqrt(2 * np.pi * var)\n",
    "        return numerator / denominator\n",
    "    \n",
    "    # Função para calcular a probabilidade posterior\n",
    "    def predict(self, X_test):\n",
    "        y_pred = [self._predict(x) for x in X_test]\n",
    "        return np.array(y_pred)\n",
    "    \n",
    "    # Função interna que calcula a probabilidade posterior para um exemplo\n",
    "    def _predict(self, x):\n",
    "        posteriors = []\n",
    "        \n",
    "        for c in self.classes:\n",
    "            prior = np.log(self.priors[c])  # Probabilidade a priori\n",
    "            conditional = np.sum(np.log(self.gaussian_pdf(c, x)))  # Verossimilhança\n",
    "            posterior = prior + conditional  # Posterior\n",
    "            posteriors.append(posterior)\n",
    "        \n",
    "        return self.classes[np.argmax(posteriors)]  # Retorna a classe com maior probabilidade\n",
    "\n",
    "# Exemplo de uso\n",
    "if __name__ == \"__main__\":\n",
    "    # Exemplo de dados: 2 features\n",
    "    X_train = np.array([[1, 2], [2, 3], [3, 4], [4, 5], [5, 6]])\n",
    "    y_train = np.array([0, 0, 1, 1, 1])\n",
    "\n",
    "    X_test = np.array([[1.5, 2.5], [3.5, 4.5]])\n",
    "\n",
    "    # Instancia o classificador Naive Bayes\n",
    "    nb = NaiveBayes()\n",
    "    \n",
    "    # Treina o modelo\n",
    "    nb.fit(X_train, y_train)\n",
    "    \n",
    "    # Faz a predição\n",
    "    predictions = nb.predict(X_test)\n",
    "    \n",
    "    print(\"Predições:\", predictions)\n",
    "```\n",
    "\n",
    "### Explicação:\n",
    "1. **`fit(self, X_train, y_train)`**:\n",
    "   - Calcula a média, a variância e as probabilidades a priori para cada classe. A suposição é que as características seguem uma distribuição normal (Gaussiana), então armazenamos a média e a variância de cada característica para cada classe.\n",
    "   \n",
    "2. **`gaussian_pdf(self, class_idx, x)`**:\n",
    "   - Função que calcula a densidade de probabilidade Gaussiana, dada uma amostra, para uma determinada classe. Isso é utilizado para calcular a verossimilhança de uma amostra pertencer a uma classe.\n",
    "\n",
    "3. **`predict(self, X_test)`**:\n",
    "   - Calcula a probabilidade posterior para cada classe e retorna a classe com a maior probabilidade.\n",
    "\n",
    "4. **_Exemplo de uso_**:\n",
    "   - No final, temos um exemplo de como o algoritmo pode ser utilizado, com um conjunto de treino simples e um conjunto de teste para fazer a predição.\n",
    "\n",
    "### Fórmulas:\n",
    "- A densidade de probabilidade Gaussiana para cada atributo \\( x_i \\) é calculada como:\n",
    "  \n",
    "  \\[\n",
    "  P(x_i|c) = \\frac{1}{\\sqrt{2\\pi \\sigma_c^2}} \\exp\\left(-\\frac{(x_i - \\mu_c)^2}{2\\sigma_c^2}\\right)\n",
    "  \\]\n",
    "  \n",
    "  Onde \\( \\mu_c \\) e \\( \\sigma_c \\) são a média e a variância da classe \\( c \\) para a característica \\( x_i \\).\n",
    "\n",
    "- A probabilidade posterior é:\n",
    "  \n",
    "  \\[\n",
    "  P(c|x) \\propto P(c) \\prod_{i=1}^{n} P(x_i|c)\n",
    "  \\]\n",
    "\n",
    "Se precisar de ajustes ou mais explicações, me avise!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NaiveBayes:\n",
    "    def fit(self, X_train, y_train):\n",
    "        # Separar por classe\n",
    "        self.classes = np.unique(y_train)\n",
    "        self.mean = {}\n",
    "        self.var = {}\n",
    "        self.priors = {}\n",
    "        \n",
    "        # Para cada classe\n",
    "        for c in self.classes:\n",
    "            X_c = X_train[y_train == c]\n",
    "            self.mean[c] = np.mean(X_c, axis=0)\n",
    "            self.var[c] = np.var(X_c, axis=0)\n",
    "            self.priors[c] = X_c.shape[0] / X_train.shape[0]\n",
    "\n",
    "    # Função para calcular a densidade de probabilidade Gaussiana\n",
    "    def gaussian_pdf(self, class_idx, x):\n",
    "        mean = self.mean[class_idx]\n",
    "        var = self.var[class_idx]\n",
    "        numerator = np.exp(-(x - mean) ** 2 / (2 * var))\n",
    "        denominator = np.sqrt(2 * np.pi * var)\n",
    "        return numerator / denominator\n",
    "    \n",
    "    # Função para calcular a probabilidade posterior\n",
    "    def predict(self, X_test):\n",
    "        y_pred = [self._predict(x) for x in X_test]\n",
    "        return np.array(y_pred)\n",
    "    \n",
    "    # Função interna que calcula a probabilidade posterior para um exemplo\n",
    "    def _predict(self, x):\n",
    "        posteriors = []\n",
    "        \n",
    "        for c in self.classes:\n",
    "            prior = np.log(self.priors[c])  # Probabilidade a priori\n",
    "            conditional = np.sum(np.log(self.gaussian_pdf(c, x)))  # Verossimilhança\n",
    "            posterior = prior + conditional  # Posterior\n",
    "            posteriors.append(posterior)\n",
    "        \n",
    "        return self.classes[np.argmax(posteriors)]  # Retorna a classe com maior probabilidade\n",
    "\n",
    "# Exemplo de uso\n",
    "if __name__ == \"__main__\":\n",
    "    # Exemplo de dados: 2 features\n",
    "    X_train = np.array([[1, 2], [2, 3], [3, 4], [4, 5], [5, 6]])\n",
    "    y_train = np.array([0, 0, 1, 1, 1])\n",
    "\n",
    "    X_test = np.array([[1.5, 2.5], [3.5, 4.5]])\n",
    "\n",
    "    # Instancia o classificador Naive Bayes\n",
    "    nb = NaiveBayes()\n",
    "    \n",
    "    # Treina o modelo\n",
    "    nb.fit(X_train, y_train)\n",
    "    \n",
    "    # Faz a predição\n",
    "    predictions = nb.predict(X_test)\n",
    "    \n",
    "    print(\"Predições:\", predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Terceiro prompt: Arvore de decisao\n",
    "Implemente um algoritmo de arvore de decisao em python sem usar scikit-leanr, ou seja, from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui está uma implementação de uma árvore de decisão do zero em Python, sem o uso da biblioteca `scikit-learn`. A implementação utiliza o critério de **Gini** para dividir os dados:\n",
    "\n",
    "### Passo 1: Cálculo do Índice Gini\n",
    "O índice Gini mede a impureza de uma divisão, ou seja, quão mista estão as classes.\n",
    "\n",
    "### Passo 2: Funções de Divisão\n",
    "Precisamos de uma função para dividir os dados com base em um valor em uma coluna específica.\n",
    "\n",
    "### Passo 3: Construção da Árvore\n",
    "A árvore de decisão é construída de forma recursiva, dividindo os dados até encontrar folhas puras ou atingir um critério de parada (como profundidade máxima).\n",
    "\n",
    "### Passo 4: Função de Previsão\n",
    "Depois que a árvore é construída, a função de previsão é utilizada para classificar novas amostras.\n",
    "\n",
    "### Código:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Função para calcular o índice Gini de um grupo de amostras\n",
    "def gini(groups, classes):\n",
    "    # Número total de amostras\n",
    "    n_instances = float(sum([len(group) for group in groups]))\n",
    "    \n",
    "    gini_index = 0.0\n",
    "    for group in groups:\n",
    "        size = len(group)\n",
    "        if size == 0:\n",
    "            continue\n",
    "        score = 0.0\n",
    "        # Proporção de cada classe no grupo\n",
    "        for class_val in classes:\n",
    "            p = [row[-1] for row in group].count(class_val) / size\n",
    "            score += p * p\n",
    "        gini_index += (1.0 - score) * (size / n_instances)\n",
    "    \n",
    "    return gini_index\n",
    "\n",
    "# Função para dividir os dados em dois grupos com base em um valor específico de uma coluna\n",
    "def test_split(index, value, dataset):\n",
    "    left, right = [], []\n",
    "    for row in dataset:\n",
    "        if row[index] < value:\n",
    "            left.append(row)\n",
    "        else:\n",
    "            right.append(row)\n",
    "    return left, right\n",
    "\n",
    "# Selecionar a melhor divisão do dataset\n",
    "def get_split(dataset):\n",
    "    class_values = list(set(row[-1] for row in dataset))\n",
    "    b_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
    "    for index in range(len(dataset[0])-1):\n",
    "        for row in dataset:\n",
    "            groups = test_split(index, row[index], dataset)\n",
    "            gini_index = gini(groups, class_values)\n",
    "            if gini_index < b_score:\n",
    "                b_index, b_value, b_score, b_groups = index, row[index], gini_index, groups\n",
    "    return {'index': b_index, 'value': b_value, 'groups': b_groups}\n",
    "\n",
    "# Criar um nó folha\n",
    "def to_terminal(group):\n",
    "    outcomes = [row[-1] for row in group]\n",
    "    return max(set(outcomes), key=outcomes.count)\n",
    "\n",
    "# Dividir os nós, criando sub-árvores de forma recursiva ou folhas\n",
    "def split(node, max_depth, min_size, depth):\n",
    "    left, right = node['groups']\n",
    "    del(node['groups'])\n",
    "    # Verificar se não há divisão\n",
    "    if not left or not right:\n",
    "        node['left'] = node['right'] = to_terminal(left + right)\n",
    "        return\n",
    "    # Verificar profundidade máxima\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "        return\n",
    "    # Processar o nó esquerdo\n",
    "    if len(left) <= min_size:\n",
    "        node['left'] = to_terminal(left)\n",
    "    else:\n",
    "        node['left'] = get_split(left)\n",
    "        split(node['left'], max_depth, min_size, depth+1)\n",
    "    # Processar o nó direito\n",
    "    if len(right) <= min_size:\n",
    "        node['right'] = to_terminal(right)\n",
    "    else:\n",
    "        node['right'] = get_split(right)\n",
    "        split(node['right'], max_depth, min_size, depth+1)\n",
    "\n",
    "# Construir uma árvore de decisão\n",
    "def build_tree(train, max_depth, min_size):\n",
    "    root = get_split(train)\n",
    "    split(root, max_depth, min_size, 1)\n",
    "    return root\n",
    "\n",
    "# Fazer uma previsão com a árvore de decisão\n",
    "def predict(node, row):\n",
    "    if row[node['index']] < node['value']:\n",
    "        if isinstance(node['left'], dict):\n",
    "            return predict(node['left'], row)\n",
    "        else:\n",
    "            return node['left']\n",
    "    else:\n",
    "        if isinstance(node['right'], dict):\n",
    "            return predict(node['right'], row)\n",
    "        else:\n",
    "            return node['right']\n",
    "\n",
    "# Exemplo de uso\n",
    "if __name__ == '__main__':\n",
    "    # Dataset de exemplo: [característica1, característica2, ..., classe]\n",
    "    dataset = [[2.771244718, 1.784783929, 0],\n",
    "               [1.728571309, 1.169761413, 0],\n",
    "               [3.678319846, 2.81281357, 0],\n",
    "               [3.961043357, 2.61995032, 0],\n",
    "               [2.999208922, 2.209014212, 0],\n",
    "               [7.497545867, 3.162953546, 1],\n",
    "               [9.00220326, 3.339047188, 1],\n",
    "               [7.444542326, 0.476683375, 1],\n",
    "               [10.12493903, 3.234550982, 1],\n",
    "               [6.642287351, 3.319983761, 1]]\n",
    "\n",
    "    # Definindo os parâmetros da árvore\n",
    "    max_depth = 3\n",
    "    min_size = 1\n",
    "\n",
    "    # Construir a árvore\n",
    "    tree = build_tree(dataset, max_depth, min_size)\n",
    "\n",
    "    # Fazer previsões\n",
    "    for row in dataset:\n",
    "        prediction = predict(tree, row)\n",
    "        print('Esperado=%d, Previsto=%d' % (row[-1], prediction))\n",
    "```\n",
    "\n",
    "### Explicação:\n",
    "1. **gini**: Calcula o índice Gini para um conjunto de grupos.\n",
    "2. **test_split**: Divide o conjunto de dados em dois grupos com base no valor de uma característica.\n",
    "3. **get_split**: Encontra a melhor divisão possível do dataset, retornando o índice da coluna e o valor que proporcionam a menor impureza Gini.\n",
    "4. **split**: Realiza a divisão recursiva dos nós.\n",
    "5. **build_tree**: Constrói a árvore de decisão.\n",
    "6. **predict**: Faz previsões com base na árvore gerada.\n",
    "\n",
    "### Testando\n",
    "O código usa um pequeno dataset para testar a construção da árvore e as previsões feitas com ela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Função para calcular o índice Gini de um grupo de amostras\n",
    "def gini(groups, classes):\n",
    "    # Número total de amostras\n",
    "    n_instances = float(sum([len(group) for group in groups]))\n",
    "    \n",
    "    gini_index = 0.0\n",
    "    for group in groups:\n",
    "        size = len(group)\n",
    "        if size == 0:\n",
    "            continue\n",
    "        score = 0.0\n",
    "        # Proporção de cada classe no grupo\n",
    "        for class_val in classes:\n",
    "            p = [row[-1] for row in group].count(class_val) / size\n",
    "            score += p * p\n",
    "        gini_index += (1.0 - score) * (size / n_instances)\n",
    "    \n",
    "    return gini_index\n",
    "\n",
    "# Função para dividir os dados em dois grupos com base em um valor específico de uma coluna\n",
    "def test_split(index, value, dataset):\n",
    "    left, right = [], []\n",
    "    for row in dataset:\n",
    "        if row[index] < value:\n",
    "            left.append(row)\n",
    "        else:\n",
    "            right.append(row)\n",
    "    return left, right\n",
    "\n",
    "# Selecionar a melhor divisão do dataset\n",
    "def get_split(dataset):\n",
    "    class_values = list(set(row[-1] for row in dataset))\n",
    "    b_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
    "    for index in range(len(dataset[0])-1):\n",
    "        for row in dataset:\n",
    "            groups = test_split(index, row[index], dataset)\n",
    "            gini_index = gini(groups, class_values)\n",
    "            if gini_index < b_score:\n",
    "                b_index, b_value, b_score, b_groups = index, row[index], gini_index, groups\n",
    "    return {'index': b_index, 'value': b_value, 'groups': b_groups}\n",
    "\n",
    "# Criar um nó folha\n",
    "def to_terminal(group):\n",
    "    outcomes = [row[-1] for row in group]\n",
    "    return max(set(outcomes), key=outcomes.count)\n",
    "\n",
    "# Dividir os nós, criando sub-árvores de forma recursiva ou folhas\n",
    "def split(node, max_depth, min_size, depth):\n",
    "    left, right = node['groups']\n",
    "    del(node['groups'])\n",
    "    # Verificar se não há divisão\n",
    "    if not left or not right:\n",
    "        node['left'] = node['right'] = to_terminal(left + right)\n",
    "        return\n",
    "    # Verificar profundidade máxima\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "        return\n",
    "    # Processar o nó esquerdo\n",
    "    if len(left) <= min_size:\n",
    "        node['left'] = to_terminal(left)\n",
    "    else:\n",
    "        node['left'] = get_split(left)\n",
    "        split(node['left'], max_depth, min_size, depth+1)\n",
    "    # Processar o nó direito\n",
    "    if len(right) <= min_size:\n",
    "        node['right'] = to_terminal(right)\n",
    "    else:\n",
    "        node['right'] = get_split(right)\n",
    "        split(node['right'], max_depth, min_size, depth+1)\n",
    "\n",
    "# Construir uma árvore de decisão\n",
    "def build_tree(train, max_depth, min_size):\n",
    "    root = get_split(train)\n",
    "    split(root, max_depth, min_size, 1)\n",
    "    return root\n",
    "\n",
    "# Fazer uma previsão com a árvore de decisão\n",
    "def predict(node, row):\n",
    "    if row[node['index']] < node['value']:\n",
    "        if isinstance(node['left'], dict):\n",
    "            return predict(node['left'], row)\n",
    "        else:\n",
    "            return node['left']\n",
    "    else:\n",
    "        if isinstance(node['right'], dict):\n",
    "            return predict(node['right'], row)\n",
    "        else:\n",
    "            return node['right']\n",
    "\n",
    "# Exemplo de uso\n",
    "if __name__ == '__main__':\n",
    "    # Dataset de exemplo: [característica1, característica2, ..., classe]\n",
    "    dataset = [[2.771244718, 1.784783929, 0],\n",
    "               [1.728571309, 1.169761413, 0],\n",
    "               [3.678319846, 2.81281357, 0],\n",
    "               [3.961043357, 2.61995032, 0],\n",
    "               [2.999208922, 2.209014212, 0],\n",
    "               [7.497545867, 3.162953546, 1],\n",
    "               [9.00220326, 3.339047188, 1],\n",
    "               [7.444542326, 0.476683375, 1],\n",
    "               [10.12493903, 3.234550982, 1],\n",
    "               [6.642287351, 3.319983761, 1]]\n",
    "\n",
    "    # Definindo os parâmetros da árvore\n",
    "    max_depth = 3\n",
    "    min_size = 1\n",
    "\n",
    "    # Construir a árvore\n",
    "    tree = build_tree(dataset, max_depth, min_size)\n",
    "\n",
    "    # Fazer previsões\n",
    "    for row in dataset:\n",
    "        prediction = predict(tree, row)\n",
    "        print('Esperado=%d, Previsto=%d' % (row[-1], prediction))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
